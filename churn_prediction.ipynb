{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YD8VVw_kNyvO",
        "gwRT-ZLHNw5Q",
        "Y3v-XaaCC3M2",
        "dS6iuSQZE-GF",
        "fItg_qsiC5TU",
        "sJv2gyGlYC8w",
        "p_WSCzjNYHgm",
        "81CmosoxZrC5",
        "5ltuxmNBntDk",
        "eIln933QbO4H"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "YD8VVw_kNyvO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0IWqaXP49qo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "gwRT-ZLHNw5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading & Initial Exploration"
      ],
      "metadata": {
        "id": "yQ1Sd7f9KMQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = './drive/MyDrive/Projects/data/DS_2/'\n",
        "train = pd.read_csv(path + 'bank_data_train.csv')\n",
        "test = pd.read_csv(path + 'bank_data_test.csv')"
      ],
      "metadata": {
        "id": "7ndtmnhaBY39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'TARGET'"
      ],
      "metadata": {
        "id": "1dLH1ucOm2LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, test.shape)\n",
        "print(train[target].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IPNjpwFJPHj",
        "outputId": "d70d9704-fe57-4b23-df28-192965044244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(355190, 116) (88798, 116)\n",
            "TARGET\n",
            "0    0.918565\n",
            "1    0.081435\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Train-Test Split with Stratification"
      ],
      "metadata": {
        "id": "IvYXqHv4STva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=target)\n",
        "y = train[target]\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42)"
      ],
      "metadata": {
        "id": "kT8p1y7QJmlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imputation"
      ],
      "metadata": {
        "id": "XCr-HBzOLF3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X_train.select_dtypes(exclude='object').columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "for df in [X_train, X_val, X_test]:\n",
        "    df[num_cols] = num_imputer.fit_transform(X_train[num_cols]) if df is X_train else num_imputer.transform(df[num_cols])\n",
        "    df[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols]) if df is X_train else cat_imputer.transform(df[cat_cols])"
      ],
      "metadata": {
        "id": "g4XuQVCCJ7k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Frequency encoding categorical columns"
      ],
      "metadata": {
        "id": "dbD6_iZ3LKru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cat_cols:\n",
        "    freq = X_train[col].value_counts(normalize=True)\n",
        "    X_train[col] = X_train[col].map(freq)\n",
        "    X_val[col] = X_val[col].map(freq).fillna(0)\n",
        "    X_test[col] = test[col].map(freq).fillna(0)"
      ],
      "metadata": {
        "id": "sJsH9m-GSPTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Outlier clipping by IQR"
      ],
      "metadata": {
        "id": "tKIxMoP3LM2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols:\n",
        "    Q1 = X_train[col].quantile(0.25)\n",
        "    Q3 = X_train[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    for df in [X_train, X_val, X_test]:\n",
        "        df[col] = df[col].clip(lower, upper)"
      ],
      "metadata": {
        "id": "3OIbnLXlU7L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling"
      ],
      "metadata": {
        "id": "hIHmZDq2LRPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
        "X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)"
      ],
      "metadata": {
        "id": "A9wlyNvYVtK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection via L1 LogisticRegression"
      ],
      "metadata": {
        "id": "EcprucrIOrQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(penalty='l1', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "selector = SelectFromModel(model, prefit=True)\n",
        "\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_val_selected = selector.transform(X_val)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "X_train.columns[selector.get_support()]"
      ],
      "metadata": {
        "id": "cew1jXoTOnII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa4b98a-22a0-49ef-a3d0-139ba052c4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ID', 'AMOUNT_RUB_CLO_PRC', 'AMOUNT_RUB_SUP_PRC', 'CLNT_TRUST_RELATION',\n",
              "       'APP_MARITAL_STATUS', 'REST_AVG_CUR', 'APP_KIND_OF_PROP_HABITATION',\n",
              "       'CLNT_JOB_POSITION_TYPE', 'AMOUNT_RUB_NAS_PRC', 'CLNT_JOB_POSITION',\n",
              "       'APP_DRIVING_LICENSE', 'TRANS_COUNT_SUP_PRC', 'APP_EDUCATION',\n",
              "       'TRANS_COUNT_NAS_PRC', 'APP_TRAVEL_PASS', 'CR_PROD_CNT_TOVR', 'APP_CAR',\n",
              "       'APP_POSITION_TYPE', 'TRANS_COUNT_ATM_PRC', 'AMOUNT_RUB_ATM_PRC', 'AGE',\n",
              "       'APP_EMP_TYPE', 'REST_DYNAMIC_CUR_1M', 'REST_DYNAMIC_CUR_3M',\n",
              "       'CNT_TRAN_SUP_TENDENCY3M', 'TURNOVER_DYNAMIC_CUR_1M',\n",
              "       'SUM_TRAN_SUP_TENDENCY3M', 'CNT_TRAN_ATM_TENDENCY3M',\n",
              "       'CNT_TRAN_ATM_TENDENCY1M', 'SUM_TRAN_ATM_TENDENCY3M',\n",
              "       'SUM_TRAN_ATM_TENDENCY1M', 'TURNOVER_DYNAMIC_CUR_3M', 'PACK',\n",
              "       'CLNT_SETUP_TENOR', 'TRANS_AMOUNT_TENDENCY3M', 'TRANS_CNT_TENDENCY3M'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Models"
      ],
      "metadata": {
        "id": "pTERY3hVWLFg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Naive Classifier"
      ],
      "metadata": {
        "id": "Y3v-XaaCC3M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy = DummyClassifier(strategy='most_frequent')\n",
        "dummy.fit(X_train_selected, y_train)\n",
        "y_pred_dummy = dummy.predict(X_val_selected)\n",
        "y_proba_dummy = dummy.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "print(\"Dummy Classifier metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_dummy))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_dummy))\n",
        "print(classification_report(y_val, y_pred_dummy))"
      ],
      "metadata": {
        "id": "EEWG82bVbDgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e0a7e3b-d219-4db0-d6ff-4e861f79ab7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy Classifier metrics:\n",
            "Accuracy: 0.918564711844365\n",
            "ROC AUC: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.00      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.46      0.50      0.48     71038\n",
            "weighted avg       0.84      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest"
      ],
      "metadata": {
        "id": "dS6iuSQZE-GF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [20, 30],\n",
        "    'max_depth': [5, 10],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(rf, param_grid, cv=2, scoring='roc_auc', verbose=1)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_rf.fit(X_train_selected, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Random Forest GridSearch training time: {end_time - start_time:.2f}s\")\n",
        "print(\"Best params:\", grid_rf.best_params_)\n",
        "\n",
        "best_rf = grid_rf.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_val_selected)\n",
        "y_proba_rf = best_rf.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "print(\"Random Forest metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_rf))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_rf))\n",
        "print(classification_report(y_val, y_pred_rf))"
      ],
      "metadata": {
        "id": "XF_LsgzgbFOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d045e1e3-4aa7-4232-a61b-e09dbe0adca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "Random Forest GridSearch training time: 158.58s\n",
            "Best params: {'class_weight': None, 'max_depth': 10, 'n_estimators': 30}\n",
            "Random Forest metrics:\n",
            "Accuracy: 0.9185787888172527\n",
            "ROC AUC: 0.8050296140727214\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.67      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.79      0.50      0.48     71038\n",
            "weighted avg       0.90      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric              | Value  | What it means                                       |\n",
        "| ------------------- | ------ | --------------------------------------------------- |\n",
        "| Accuracy            | 0.9186 | \\~92% overall correct predictions                   |\n",
        "| ROC AUC             | 0.8050 | Good discrimination ability (0.5=chance, 1=perfect) |\n",
        "| Precision (class 0) | 0.92   | Of predicted non-churn, 92% correct                 |\n",
        "| Recall (class 0)    | 1.00   | Model found almost all non-churn cases              |\n",
        "| Precision (class 1) | 0.67   | Of predicted churn, 67% correct                     |\n",
        "| Recall (class 1)    | 0.00   | Model detected almost **no churn cases** (bad)      |\n"
      ],
      "metadata": {
        "id": "ZyEv2Z4lZNSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scikit-learn MLPClassifier"
      ],
      "metadata": {
        "id": "fItg_qsiC5TU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(64,), (128,)],\n",
        "    'alpha': [1e-4, 1e-3],\n",
        "    'learning_rate': ['adaptive'],\n",
        "    'learning_rate_init': [0.001],\n",
        "    'activation': ['relu'],\n",
        "    'solver': ['adam']\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    MLPClassifier(max_iter=300, early_stopping=True, random_state=42),\n",
        "    param_grid,\n",
        "    cv=cv,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "grid.fit(X_train_selected, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"MLPClassifier training time: {end_time - start_time:.2f}s\")\n",
        "\n",
        "best_mlp = grid.best_estimator_\n",
        "y_pred_sklearn_mlp = best_mlp.predict(X_val_selected)\n",
        "y_proba_sklearn_mlp = best_mlp.predict_proba(X_val_selected)[:, 1]\n",
        "\n",
        "print(\"MLPClassifier metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_sklearn_mlp))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_sklearn_mlp))\n",
        "print(classification_report(y_val, y_pred_sklearn_mlp))"
      ],
      "metadata": {
        "id": "nPrWGyFwbHR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c0f75c-2173-45a5-f417-6ac82205ed41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "MLPClassifier training time: 75.60s\n",
            "MLPClassifier metrics:\n",
            "Accuracy: 0.9185787888172527\n",
            "ROC AUC: 0.7371770890938549\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.60      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.76      0.50      0.48     71038\n",
            "weighted avg       0.89      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Keras MLP"
      ],
      "metadata": {
        "id": "sJv2gyGlYC8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train_selected.shape[1]\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(input_dim,)),\n",
        "    Dropout(0.3),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train_selected, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_val_selected, y_val),\n",
        "    validation_freq=3,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Keras model training time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "y_proba_keras_mlp = model.predict(X_val_selected).flatten()\n",
        "y_pred_keras_mlp = (y_proba_keras_mlp > 0.5).astype(int)\n",
        "\n",
        "print(\"Keras MLP metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_keras_mlp))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_keras_mlp))\n",
        "print(classification_report(y_val, y_pred_keras_mlp))"
      ],
      "metadata": {
        "id": "7yeyZM4qbI7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "49de81cf-365c-43d4-9c3c-5011c9bf3579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2941 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2591 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2576 - val_accuracy: 0.9186 - val_loss: 0.2514 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2534 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2522 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2523 - val_accuracy: 0.9186 - val_loss: 0.2460 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2484 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2479 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2471 - val_accuracy: 0.9186 - val_loss: 0.2434 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2474 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2454 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2468 - val_accuracy: 0.9186 - val_loss: 0.2427 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2465 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2462 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2454 - val_accuracy: 0.9186 - val_loss: 0.2425 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2473 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2478 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2430 - val_accuracy: 0.9186 - val_loss: 0.2414 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2451 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2449 - val_accuracy: 0.9186 - val_loss: 0.2406 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2435 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2452 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2440 - val_accuracy: 0.9186 - val_loss: 0.2407 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2455 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2442 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2440 - val_accuracy: 0.9186 - val_loss: 0.2400 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2447 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2434 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2420 - val_accuracy: 0.9186 - val_loss: 0.2409 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2434 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.2425 - val_accuracy: 0.9186 - val_loss: 0.2395 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2434 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2450 - val_accuracy: 0.9186 - val_loss: 0.2407 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2438 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2448 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2430 - val_accuracy: 0.9186 - val_loss: 0.2400 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2434 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 3ms/step - accuracy: 0.9200 - loss: 0.2412 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2435 - val_accuracy: 0.9186 - val_loss: 0.2394 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2420 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2443 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9185 - loss: 0.2429 - val_accuracy: 0.9186 - val_loss: 0.2398 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2448 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2437 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - accuracy: 0.9190 - loss: 0.2417 - val_accuracy: 0.9186 - val_loss: 0.2397 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2433 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m4440/4440\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2420 - learning_rate: 0.0010\n",
            "Keras model training time: 843.53 seconds\n",
            "\u001b[1m2220/2220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
            "Keras MLP metrics:\n",
            "Accuracy: 0.918564711844365\n",
            "ROC AUC: 0.7928139181843648\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96     65253\n",
            "           1       0.00      0.00      0.00      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.46      0.50      0.48     71038\n",
            "weighted avg       0.84      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TensorFlow MLP"
      ],
      "metadata": {
        "id": "p_WSCzjNYHgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_convert_X(X):\n",
        "    if hasattr(X, \"to_numpy\"):\n",
        "        return X.to_numpy().astype(np.float32)\n",
        "    else:\n",
        "        return X.astype(np.float32)\n",
        "\n",
        "def safe_convert_y(y):\n",
        "    if hasattr(y, \"to_numpy\"):\n",
        "        return y.to_numpy().astype(np.float32).reshape(-1, 1)\n",
        "    else:\n",
        "        return y.astype(np.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "J_VCBu970b6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = safe_convert_X(X_train)\n",
        "y_train = safe_convert_y(y_train)\n",
        "X_val = safe_convert_X(X_val)\n",
        "y_val = safe_convert_y(y_val)"
      ],
      "metadata": {
        "id": "IxtkQ9vAyUta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \\\n",
        "    .shuffle(buffer_size=10000) \\\n",
        "    .batch(batch_size) \\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)) \\\n",
        "    .batch(batch_size) \\\n",
        "    .prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "gmcakr4F0sGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(tf.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # He-like initialization for weights:\n",
        "        # Using truncated normal distribution scaled by sqrt(2 / number_of_inputs)\n",
        "        init_w1 = tf.random.truncated_normal([input_dim, 64], stddev=tf.math.sqrt(2. / input_dim))\n",
        "        init_w2 = tf.random.truncated_normal([64, 32], stddev=tf.math.sqrt(2. / 64))\n",
        "        init_w3 = tf.random.truncated_normal([32, 1], stddev=tf.math.sqrt(2. / 32))\n",
        "\n",
        "        # Trainable variables (weights and biases)\n",
        "        self.W1 = tf.Variable(init_w1, name=\"W1\")        # Input → Hidden1 (64 neurons)\n",
        "        self.b1 = tf.Variable(tf.zeros([64]), name=\"b1\")\n",
        "\n",
        "        self.W2 = tf.Variable(init_w2, name=\"W2\")        # Hidden1 → Hidden2 (32 neurons)\n",
        "        self.b2 = tf.Variable(tf.zeros([32]), name=\"b2\")\n",
        "\n",
        "        self.W3 = tf.Variable(init_w3, name=\"W3\")        # Hidden2 → Output (1 neuron)\n",
        "        self.b3 = tf.Variable(tf.zeros([1]), name=\"b3\")\n",
        "\n",
        "    def __call__(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass of the network.\n",
        "        :param x: Input tensor of shape (batch_size, input_dim)\n",
        "        :param training: Boolean flag, True = apply dropout\n",
        "        \"\"\"\n",
        "\n",
        "        # First hidden layer: Linear → ReLU → Dropout\n",
        "        x = tf.matmul(x, self.W1) + self.b1   # Linear transform\n",
        "        x = tf.nn.relu(x)                     # Non-linear activation\n",
        "        if training:\n",
        "            x = tf.nn.dropout(x, rate=0.3)    # Dropout (30%) for regularization\n",
        "\n",
        "        # Second hidden layer: Linear → ReLU → Dropout\n",
        "        x = tf.matmul(x, self.W2) + self.b2\n",
        "        x = tf.nn.relu(x)\n",
        "        if training:\n",
        "            x = tf.nn.dropout(x, rate=0.3)\n",
        "\n",
        "        # Output layer: Linear → Sigmoid (probability)\n",
        "        logits = tf.matmul(x, self.W3) + self.b3\n",
        "        return tf.sigmoid(logits)             # Output in [0, 1]"
      ],
      "metadata": {
        "id": "2316vZ5ryagP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleMLP(input_dim=X_train.shape[1])\n",
        "\n",
        "# Compute class weights to handle class imbalance in the training data\n",
        "y_train_1d = y_train.flatten().astype(int)\n",
        "weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_1d), y=y_train_1d)\n",
        "\n",
        "# Create a dictionary mapping class labels to their computed weights\n",
        "class_weights_dict = {int(cls): float(w) for cls, w in zip(np.unique(y_train_1d), weights)}\n",
        "print(\"Class weights:\", class_weights_dict)\n",
        "\n",
        "def loss_fn(y_true, y_pred):\n",
        "    # Clip predictions to avoid log(0) errors in loss calculation\n",
        "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)\n",
        "    # Assign weight based on true class label (0 or 1)\n",
        "    weights = tf.where(tf.equal(y_true, 1), class_weights_dict[1], class_weights_dict[0])\n",
        "    # Compute weighted binary cross-entropy loss manually\n",
        "    loss = -(weights * (y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred)))\n",
        "    # Return mean loss over the batch\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "# Use Adam optimizer with a learning rate of 0.001\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "@tf.function  # Compile train_step into a TensorFlow graph for performance\n",
        "def train_step(x_batch, y_batch):\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass with dropout enabled (training=True)\n",
        "        y_pred = model(x_batch, training=True)\n",
        "        # Compute loss with class weights\n",
        "        loss = loss_fn(y_batch, y_pred)\n",
        "    # Compute gradients of loss w.r.t. model variables\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    # Apply gradients to update model variables\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "@tf.function  # Compile validation step for efficiency\n",
        "def val_step(x_batch, y_batch):\n",
        "    # Forward pass without dropout (training=False)\n",
        "    y_pred = model(x_batch, training=False)\n",
        "    # Compute loss for the batch\n",
        "    loss = loss_fn(y_batch, y_pred)\n",
        "    return loss, y_pred\n",
        "\n",
        "def validate():\n",
        "    val_losses = []\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    # Iterate over batches from validation dataset\n",
        "    for x_batch, y_batch in val_ds:\n",
        "        # Compute loss and predictions for current batch\n",
        "        loss, y_pred = val_step(x_batch, y_batch)\n",
        "        # Convert TensorFlow tensors to numpy arrays for aggregation\n",
        "        val_losses.append(loss.numpy())\n",
        "        all_preds.append(y_pred.numpy())\n",
        "        all_labels.append(y_batch.numpy())\n",
        "    # Compute average validation loss over all batches\n",
        "    val_loss = np.mean(val_losses)\n",
        "    # Stack all batch predictions and flatten to 1D array\n",
        "    all_preds = np.vstack(all_preds).flatten()\n",
        "    # Stack all true labels and flatten to 1D array\n",
        "    all_labels = np.vstack(all_labels).flatten()\n",
        "    # Return average validation loss, true labels, and predicted probabilities\n",
        "    return val_loss, all_labels, all_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FN4hsdU0yeSz",
        "outputId": "c1447a89-22e6-4f9f-8434-48db123e4949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: {0: 0.5443274638713929, 1: 6.139844425237683}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "patience = 5\n",
        "lr_patience = 3\n",
        "best_val_loss = np.inf\n",
        "wait = 0\n",
        "lr_wait = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    train_losses = []\n",
        "\n",
        "    # Training loop over batches\n",
        "    for x_batch, y_batch in train_ds:\n",
        "        loss = train_step(x_batch, y_batch)      # Perform one training step\n",
        "        train_losses.append(loss.numpy())        # Store batch loss\n",
        "\n",
        "    train_loss = np.mean(train_losses)           # Compute average training loss for epoch\n",
        "\n",
        "    # Validate model performance on validation set\n",
        "    val_loss, y_val_true, y_val_pred = validate()\n",
        "\n",
        "    # Calculate evaluation metrics: ROC AUC and accuracy\n",
        "    val_auc = roc_auc_score(y_val_true, y_val_pred)\n",
        "    val_acc = accuracy_score(y_val_true, y_val_pred > 0.5)\n",
        "\n",
        "    print(f\"Train loss: {train_loss:.4f} | Val loss: {val_loss:.4f} | Val ROC AUC: {val_auc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # Check if validation loss improved\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss    # Update best validation loss\n",
        "        wait = 0                   # Reset early stopping counter\n",
        "        lr_wait = 0                # Reset learning rate patience counter\n",
        "        # Save current best model weights\n",
        "        best_weights = [v.numpy() for v in model.trainable_variables]\n",
        "    else:\n",
        "        wait += 1\n",
        "        lr_wait += 1\n",
        "\n",
        "        # Reduce learning rate if no improvement for lr_patience epochs\n",
        "        if lr_wait >= lr_patience:\n",
        "            old_lr = optimizer.learning_rate.numpy()\n",
        "            new_lr = max(old_lr * 0.5, 1e-6)    # Reduce by half but not below 1e-6\n",
        "            optimizer.learning_rate.assign(new_lr)\n",
        "            print(f\"Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}\")\n",
        "            lr_wait = 0\n",
        "\n",
        "        # Trigger early stopping if no improvement for 'patience' epochs\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Training finished in {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# Restore the model weights to the best observed during training\n",
        "for var, val in zip(model.trainable_variables, best_weights):\n",
        "    var.assign(val)\n",
        "\n",
        "# Final evaluation on validation set with best weights\n",
        "val_loss, y_val_true, y_proba_tf_mlp = validate()\n",
        "y_pred_tf_mlp = (y_proba_tf_mlp > 0.5).astype(int)\n",
        "\n",
        "print(\"Final evaluation:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_val_true, y_pred_tf_mlp))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val_true, y_proba_tf_mlp))\n",
        "print(classification_report(y_val_true, y_pred_tf_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QeMDGXQ9ygpd",
        "outputId": "0b7dc701-76b0-4aa0-b726-8bd405cc1e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final evaluation:\n",
            "Accuracy: 0.630465384723669\n",
            "ROC AUC: 0.8040117343409611\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.61      0.75     65253\n",
            "         1.0       0.16      0.85      0.27      5785\n",
            "\n",
            "    accuracy                           0.63     71038\n",
            "   macro avg       0.57      0.73      0.51     71038\n",
            "weighted avg       0.91      0.63      0.71     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### NumPy MLP"
      ],
      "metadata": {
        "id": "81CmosoxZrC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_convert_X(X):\n",
        "    return X.to_numpy().astype(np.float32) if hasattr(X, \"to_numpy\") else X.astype(np.float32)\n",
        "\n",
        "def safe_convert_y(y):\n",
        "    return y.to_numpy().astype(np.float32).reshape(-1, 1) if hasattr(y, \"to_numpy\") else y.astype(np.float32).reshape(-1, 1)\n",
        "\n",
        "X_train = safe_convert_X(X_train_selected)\n",
        "X_val = safe_convert_X(X_val_selected)\n",
        "X_test = safe_convert_X(X_test_selected)\n",
        "y_train = safe_convert_y(y_train)\n",
        "y_val = safe_convert_y(y_val)\n",
        "y_test = safe_convert_y(y_test)"
      ],
      "metadata": {
        "id": "oH2diGwlhA_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    # ReLU activation: outputs x if x>0, else 0\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_deriv(x):\n",
        "    # Derivative of ReLU: 1 if x>0 else 0 (used in backprop)\n",
        "    return (x > 0).astype(np.float32)\n",
        "\n",
        "def sigmoid(x):\n",
        "    # Sigmoid activation: maps real values to (0,1)\n",
        "    x = np.clip(x, -500, 500)  # Clip to avoid overflow in exp()\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_deriv(x):\n",
        "    # Derivative of sigmoid: s * (1 - s)\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    # Binary cross-entropy loss function\n",
        "    eps = 1e-10  # small epsilon to avoid log(0)\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    # Mean negative log-likelihood over all samples\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "def binary_cross_entropy_deriv(y_true, y_pred):\n",
        "    # Derivative of binary cross-entropy loss w.r.t. predictions\n",
        "    eps = 1e-10\n",
        "    y_pred = np.clip(y_pred, eps, 1 - eps)\n",
        "    # Gradient formula for binary cross-entropy loss\n",
        "    return (y_pred - y_true) / (y_pred * (1 - y_pred))"
      ],
      "metadata": {
        "id": "h46yzBQ3fXlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, input_size, hidden_sizes=(64, 32), output_size=1, lr=0.01):\n",
        "        h1, h2 = hidden_sizes\n",
        "        self.lr = lr\n",
        "\n",
        "        # He-like initialization of weights for each layer\n",
        "        self.W1 = np.random.randn(input_size, h1) * np.sqrt(2. / input_size)\n",
        "        self.b1 = np.zeros((1, h1))  # Bias initialized to zeros\n",
        "        self.W2 = np.random.randn(h1, h2) * np.sqrt(2. / h1)\n",
        "        self.b2 = np.zeros((1, h2))\n",
        "        self.W3 = np.random.randn(h2, output_size) * np.sqrt(2. / h2)\n",
        "        self.b3 = np.zeros((1, output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward pass through the network\n",
        "        self.z1 = X @ self.W1 + self.b1  # Linear step layer 1\n",
        "        self.a1 = relu(self.z1)           # Activation ReLU layer 1\n",
        "\n",
        "        self.z2 = self.a1 @ self.W2 + self.b2  # Linear step layer 2\n",
        "        self.a2 = relu(self.z2)                 # Activation ReLU layer 2\n",
        "\n",
        "        self.z3 = self.a2 @ self.W3 + self.b3  # Linear step output layer\n",
        "        self.a3 = sigmoid(self.z3)              # Sigmoid activation output (probability)\n",
        "        return self.a3\n",
        "\n",
        "    def backward(self, X, y_true):\n",
        "        m = X.shape[0]  # Batch size\n",
        "        y_pred = self.a3\n",
        "\n",
        "        # Compute gradient for output layer (chain rule)\n",
        "        dz3 = binary_cross_entropy_deriv(y_true, y_pred) * sigmoid_deriv(self.z3)\n",
        "        dW3 = self.a2.T @ dz3 / m               # Gradient w.r.t. weights output layer\n",
        "        db3 = np.sum(dz3, axis=0, keepdims=True) / m  # Gradient w.r.t. bias output layer\n",
        "\n",
        "        # Backpropagate gradients to second hidden layer\n",
        "        dz2 = dz3 @ self.W3.T * relu_deriv(self.z2)\n",
        "        dW2 = self.a1.T @ dz2 / m\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Backpropagate gradients to first hidden layer\n",
        "        dz1 = dz2 @ self.W2.T * relu_deriv(self.z1)\n",
        "        dW1 = X.T @ dz1 / m\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Update weights and biases by gradient descent\n",
        "        self.W3 -= self.lr * dW3\n",
        "        self.b3 -= self.lr * db3\n",
        "        self.W2 -= self.lr * dW2\n",
        "        self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1\n",
        "        self.b1 -= self.lr * db1\n",
        "\n",
        "    def train(self, X, y, X_val=None, y_val=None, epochs=100, batch_size=64, patience=5, verbose=True):\n",
        "        n = X.shape[0]\n",
        "        best_val_loss = np.inf\n",
        "        wait = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Shuffle training data at each epoch to improve generalization\n",
        "            perm = np.random.permutation(n)\n",
        "            X_shuffled = X[perm]\n",
        "            y_shuffled = y[perm]\n",
        "\n",
        "            # Train in mini-batches for efficiency and stability\n",
        "            for i in range(0, n, batch_size):\n",
        "                X_batch = X_shuffled[i:i + batch_size]\n",
        "                y_batch = y_shuffled[i:i + batch_size]\n",
        "                self.forward(X_batch)           # Forward pass\n",
        "                self.backward(X_batch, y_batch)  # Backward pass and weights update\n",
        "\n",
        "            # Compute loss on full training set (for monitoring)\n",
        "            train_pred = self.forward(X)\n",
        "            train_loss = binary_cross_entropy(y, train_pred)\n",
        "\n",
        "            # Optionally compute validation loss for early stopping\n",
        "            if X_val is not None and y_val is not None:\n",
        "                val_pred = self.forward(X_val)\n",
        "                val_loss = binary_cross_entropy(y_val, val_pred)\n",
        "\n",
        "            # Print progress every 10 epochs\n",
        "            if verbose and epoch % 10 == 0:\n",
        "                print(f\"Epoch {epoch:03d} | Train Loss: {train_loss:.4f}\", end=\"\")\n",
        "                if X_val is not None and y_val is not None:\n",
        "                    print(f\" | Val Loss: {val_loss:.4f}\")\n",
        "                else:\n",
        "                    print()\n",
        "\n",
        "            # Early stopping logic based on validation loss\n",
        "            if X_val is not None and y_val is not None:\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    wait = 0\n",
        "                    # Save best weights so far\n",
        "                    best_weights = (self.W1.copy(), self.b1.copy(),\n",
        "                                    self.W2.copy(), self.b2.copy(),\n",
        "                                    self.W3.copy(), self.b3.copy())\n",
        "                else:\n",
        "                    wait += 1\n",
        "                    if wait >= patience:\n",
        "                        if verbose:\n",
        "                            print(f\"Early stopping at epoch {epoch}\")\n",
        "                        # Restore best weights before stopping\n",
        "                        self.W1, self.b1, self.W2, self.b2, self.W3, self.b3 = best_weights\n",
        "                        break\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict class labels (0 or 1) using threshold 0.5 on sigmoid output\n",
        "        return (self.forward(X) > 0.5).astype(int)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        # Predict probabilities (sigmoid output)\n",
        "        return self.forward(X)"
      ],
      "metadata": {
        "id": "sOe-tMDkfc3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_MLP = MLP(input_size=X_train.shape[1], hidden_sizes=(64, 32), lr=0.01)\n",
        "\n",
        "numpy_MLP.train(X_train, y_train, X_val, y_val, epochs=100, batch_size=128, patience=10, verbose=True)\n",
        "\n",
        "y_pred_np_mlp = numpy_MLP.predict(X_val)\n",
        "y_proba_np_mlp = numpy_MLP.predict_proba(X_val)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_pred_np_mlp))\n",
        "print(\"ROC AUC:\", roc_auc_score(y_val, y_proba_np_mlp))\n",
        "print(classification_report(y_val, y_pred_np_mlp))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4BYAENyiyLG",
        "outputId": "c7f95985-2199-4605-8077-4e01a5e0ec89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 000 | Train Loss: 0.2719 | Val Loss: 0.2720\n",
            "Epoch 010 | Train Loss: 0.2539 | Val Loss: 0.2560\n",
            "Epoch 020 | Train Loss: 0.2504 | Val Loss: 0.2535\n",
            "Epoch 030 | Train Loss: 0.2476 | Val Loss: 0.2515\n",
            "Epoch 040 | Train Loss: 0.2456 | Val Loss: 0.2502\n",
            "Epoch 050 | Train Loss: 0.2437 | Val Loss: 0.2487\n",
            "Epoch 060 | Train Loss: 0.2416 | Val Loss: 0.2471\n",
            "Epoch 070 | Train Loss: 0.2395 | Val Loss: 0.2453\n",
            "Epoch 080 | Train Loss: 0.2379 | Val Loss: 0.2442\n",
            "Epoch 090 | Train Loss: 0.2364 | Val Loss: 0.2432\n",
            "Accuracy: 0.9184661730341508\n",
            "ROC AUC: 0.7823424550788758\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      1.00      0.96     65253\n",
            "         1.0       0.46      0.01      0.01      5785\n",
            "\n",
            "    accuracy                           0.92     71038\n",
            "   macro avg       0.69      0.50      0.49     71038\n",
            "weighted avg       0.88      0.92      0.88     71038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results Summary Table"
      ],
      "metadata": {
        "id": "5ltuxmNBntDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({\n",
        "    \"Library\": [\n",
        "        \"Dummy\",\n",
        "        \"Ensemble\",\n",
        "        \"Neural network\",\n",
        "        \"Keras\",\n",
        "        \"TensorFlow\",\n",
        "        \"NumPy\"\n",
        "    ],\n",
        "    \"Algorithm\": [\n",
        "        \"DummyClassifier\",\n",
        "        \"RandomForestCLassifier\",\n",
        "        \"MLPClassifier\",\n",
        "        \"Keras MLP\",\n",
        "        \"TensorFlow MLP\",\n",
        "        \"NumPy MLP\",\n",
        "    ],\n",
        "    \"Accuracy\": [\n",
        "        accuracy_score(y_val, y_pred_dummy),\n",
        "        accuracy_score(y_val, y_pred_rf),\n",
        "        accuracy_score(y_val, y_pred_sklearn_mlp),\n",
        "        accuracy_score(y_val, y_pred_keras_mlp),\n",
        "        accuracy_score(y_val, y_pred_tf_mlp),\n",
        "        accuracy_score(y_val, y_pred_np_mlp)\n",
        "    ],\n",
        "    \"ROC AUC\": [\n",
        "        roc_auc_score(y_val, y_proba_dummy),\n",
        "        roc_auc_score(y_val, y_proba_rf),\n",
        "        roc_auc_score(y_val, y_proba_sklearn_mlp),\n",
        "        roc_auc_score(y_val, y_proba_keras_mlp),\n",
        "        roc_auc_score(y_val, y_proba_tf_mlp),\n",
        "        roc_auc_score(y_val, y_proba_np_mlp)\n",
        "    ]\n",
        "})\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "A1UwZL5InuvR",
        "outputId": "09c8d270-68a0-4f89-b26e-44ed72b80a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Library               Algorithm  Accuracy   ROC AUC\n",
              "0           Dummy         DummyClassifier  0.918565  0.500000\n",
              "1        Ensemble  RandomForestCLassifier  0.918579  0.805030\n",
              "2  Neural network           MLPClassifier  0.918579  0.737177\n",
              "3           Keras               Keras MLP  0.918565  0.792814\n",
              "4      TensorFlow          TensorFlow MLP  0.630465  0.804012\n",
              "5           NumPy               NumPy MLP  0.918466  0.782342"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e8254b0-2fa6-4b6d-8a66-fe5e3720d950\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Library</th>\n",
              "      <th>Algorithm</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>ROC AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dummy</td>\n",
              "      <td>DummyClassifier</td>\n",
              "      <td>0.918565</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>RandomForestCLassifier</td>\n",
              "      <td>0.918579</td>\n",
              "      <td>0.805030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Neural network</td>\n",
              "      <td>MLPClassifier</td>\n",
              "      <td>0.918579</td>\n",
              "      <td>0.737177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Keras</td>\n",
              "      <td>Keras MLP</td>\n",
              "      <td>0.918565</td>\n",
              "      <td>0.792814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TensorFlow</td>\n",
              "      <td>TensorFlow MLP</td>\n",
              "      <td>0.630465</td>\n",
              "      <td>0.804012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NumPy</td>\n",
              "      <td>NumPy MLP</td>\n",
              "      <td>0.918466</td>\n",
              "      <td>0.782342</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e8254b0-2fa6-4b6d-8a66-fe5e3720d950')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7e8254b0-2fa6-4b6d-8a66-fe5e3720d950 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7e8254b0-2fa6-4b6d-8a66-fe5e3720d950');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-aeba1c8c-8340-40be-a118-26b0d6539699\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aeba1c8c-8340-40be-a118-26b0d6539699')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-aeba1c8c-8340-40be-a118-26b0d6539699 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_192c9c7c-96bb-4ab4-bac1-7dab7afe6be9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_192c9c7c-96bb-4ab4-bac1-7dab7afe6be9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Library\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Dummy\",\n          \"Ensemble\",\n          \"NumPy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Algorithm\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"DummyClassifier\",\n          \"RandomForestCLassifier\",\n          \"NumPy MLP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11761031863121932,\n        \"min\": 0.630465384723669,\n        \"max\": 0.9185787888172527,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9185787888172527,\n          0.9184661730341508,\n          0.918564711844365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11870863392600352,\n        \"min\": 0.5,\n        \"max\": 0.8050296140727214,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.5,\n          0.8050296140727214,\n          0.7823424550788758\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission"
      ],
      "metadata": {
        "id": "eIln933QbO4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = numpy_MLP.predict_proba(X_test_selected).flatten()\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test['ID'],\n",
        "    'TARGET': y_pred_proba\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "EMA9aSYzbPTV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}